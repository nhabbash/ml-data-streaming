{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ebef63f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f3cab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nassim/dev/mlops-project\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f9f649",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from src.utils import *\n",
    "from src.models import *\n",
    "from src.data import *\n",
    "\n",
    "import wandb\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42617e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_device(cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f8945cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdodicin\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39f4f946",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nassim/miniconda3/envs/ml-env/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 1, 28, 28]), torch.Size([128]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "val_ratio = 0.15\n",
    "num_workers = 8\n",
    "dm = FashionMNISTDataModule(batch_size=batch_size, num_classes=num_classes, val_ratio=val_ratio, num_workers=8)\n",
    "dm.setup()\n",
    "\n",
    "val_samples = next(iter(dm.val_dataloader()))\n",
    "val_imgs, val_labels = val_samples[0], val_samples[1]\n",
    "val_imgs.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5046d2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split:\n",
      "Train: 0.73\n",
      "Val: 0.13\n",
      "Test: 0.14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = len(dm.train)+len(dm.val)+len(dm.test)\n",
    "\n",
    "print(\"Dataset split:\\n\"+\n",
    "      \"Train: {:.2f}\\n\".format(len(dm.train)/n)+\n",
    "      \"Val: {:.2f}\\n\".format(len(dm.val)/n)+\n",
    "      \"Test: {:.2f}\\n\".format(len(dm.test)/n)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "732156c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking class weights\n",
    "# class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "# num_classes = len(class_names)\n",
    "\n",
    "# y_train = dm.train.dataset.targets\n",
    "# counts = np.bincount(y_train)\n",
    "# class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
    "# print (f\"counts: {counts}\\nweights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab2dbe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import ModelPruning\n",
    "from pytorch_lightning.callbacks import QuantizationAwareTraining\n",
    "\n",
    "input_dim = val_imgs.shape[1:]\n",
    "\n",
    "model = ResNet18(input_dim, num_classes, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5edc1e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nassim/miniconda3/envs/ml-env/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:446: UserWarning: Checkpoint directory data/notebook_run/models/ exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">northern-eon-57</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/dodicin/mlops-project\" target=\"_blank\">https://wandb.ai/dodicin/mlops-project</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/dodicin/mlops-project/runs/1so8owze\" target=\"_blank\">https://wandb.ai/dodicin/mlops-project/runs/1so8owze</a><br/>\n",
       "                Run data is saved locally in <code>/home/nassim/dev/mlops-project/wandb/run-20210901_132454-1so8owze</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/nassim/miniconda3/envs/ml-env/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | accuracy          | Accuracy         | 0     \n",
      "1 | loss              | CrossEntropyLoss | 0     \n",
      "2 | quant             | QuantStub        | 0     \n",
      "3 | dequant           | DeQuantStub      | 0     \n",
      "4 | feature_extractor | ResNet           | 11.7 M\n",
      "5 | classifier        | Linear           | 10.0 K\n",
      "-------------------------------------------------------\n",
      "10.0 K    Trainable params\n",
      "11.7 M    Non-trainable params\n",
      "11.7 M    Total params\n",
      "46.763    Total estimated model params size (MB)\n",
      "/home/nassim/miniconda3/envs/ml-env/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c25295f0134848990c5aece978d9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR finder stopped early after 97 steps due to diverging loss.\n",
      "Restoring states from the checkpoint file at /home/nassim/dev/mlops-project/lr_find_temp_model.ckpt\n",
      "Restored all states from the checkpoint file at /home/nassim/dev/mlops-project/lr_find_temp_model.ckpt\n",
      "Learning rate set to 0.0010964781961431851\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | accuracy          | Accuracy         | 0     \n",
      "1 | loss              | CrossEntropyLoss | 0     \n",
      "2 | quant             | QuantStub        | 0     \n",
      "3 | dequant           | DeQuantStub      | 0     \n",
      "4 | feature_extractor | ResNet           | 11.7 M\n",
      "5 | classifier        | Linear           | 10.0 K\n",
      "-------------------------------------------------------\n",
      "10.0 K    Trainable params\n",
      "11.7 M    Non-trainable params\n",
      "11.7 M    Total params\n",
      "46.763    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4cc29a51d524c79a971861459a5f972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603df82bfcc64ec08d1b90479dd29665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 96it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applied `L1Unstructured`. Pruned: 0/12224004 (0.00%) -> 2338151/12224004 (19.13%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applied `L1Unstructured`. Pruned: 2338151/12224004 (19.13%) -> 4208672/12224004 (34.43%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applied `L1Unstructured`. Pruned: 4208672/12224004 (34.43%) -> 5705088/12224004 (46.67%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applied `L1Unstructured`. Pruned: 5705088/12224004 (46.67%) -> 6902221/12224004 (56.46%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applied `L1Unstructured`. Pruned: 6902221/12224004 (56.46%) -> 7859928/12224004 (64.30%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applied `L1Unstructured`. Pruned: 7859928/12224004 (64.30%) -> 8626093/12224004 (70.57%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applied `L1Unstructured`. Pruned: 8626093/12224004 (70.57%) -> 9239025/12224004 (75.58%)\n",
      "/home/nassim/miniconda3/envs/ml-env/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.teardown has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.teardown.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be629b71b7ef4e529cd9878171732e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_accuracy': 0.6388000249862671, 'test_loss': 1.1287829875946045}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.1287829875946045, 'test_accuracy': 0.6388000249862671}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_CKPT_PATH = 'data/notebook_run/models/'\n",
    "MODEL_CKPT = 'model-{epoch:02d}-{val_loss:.2f}'\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    filename=MODEL_CKPT,\n",
    "    dirpath=MODEL_CKPT_PATH,\n",
    "    save_top_k=3,\n",
    "    mode='min')\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='val_loss',\n",
    "   patience=3,\n",
    "   verbose=False,\n",
    "   mode='min'\n",
    ")\n",
    "\n",
    "pruning_callback = ModelPruning(\n",
    "    pruning_fn=\"l1_unstructured\", \n",
    "    amount=0.1, \n",
    "    verbose=1,\n",
    "    use_global_unstructured=True\n",
    ")\n",
    "\n",
    "#quantization_callback = QuantizationAwareTraining() # Usable on another backend\n",
    "\n",
    "run = wandb.init(project='mlops-project')\n",
    "wandb_logger = WandbLogger(project='mlops-project', job_type='train', log_model=True)\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = pl.Trainer(max_epochs=10,\n",
    "                     auto_lr_find=True,\n",
    "                     #auto_scale_batch_size=\"binsearch\", # Do not use on WSL\n",
    "                     gpus=1,\n",
    "                     progress_bar_refresh_rate=20,\n",
    "                     logger=wandb_logger,\n",
    "                     callbacks=[early_stop_callback,\n",
    "                                checkpoint_callback,\n",
    "                                pruning_callback,\n",
    "                                ImagePredictionLogger()],\n",
    "                     checkpoint_callback=True)\n",
    "\n",
    "# Experiment identifiers\n",
    "run_id = trainer.logger.experiment.id\n",
    "project = trainer.logger.experiment.project\n",
    "entity = trainer.logger.experiment.entity\n",
    "\n",
    "trainer.tune(model, datamodule=dm)\n",
    "trainer.fit(model, dm)\n",
    "trainer.test(ckpt_path=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9768c54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = trainer.checkpoint_callback.best_model_path # Getting checkpoint ref from PL\n",
    "inference_model = ResNet18.load_from_checkpoint(best_model)\n",
    "y_true, y_pred = evaluate(inference_model, dm.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b2001e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "binary_ground_truth = label_binarize(y_true,\n",
    "                                     classes=np.arange(0, 10).tolist())\n",
    "\n",
    "precision_micro, recall_micro, _ = precision_recall_curve(binary_ground_truth.ravel(),\n",
    "                                                          y_pred.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2bbc801",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6874<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 134.58MB of 134.87MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.9978488…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/nassim/dev/mlops-project/wandb/run-20210901_132454-1so8owze/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/nassim/dev/mlops-project/wandb/run-20210901_132454-1so8owze/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>144</td></tr><tr><td>_timestamp</td><td>1630495638</td></tr><tr><td>_step</td><td>71</td></tr><tr><td>train_loss</td><td>0.56464</td></tr><tr><td>train_accuracy</td><td>0.75781</td></tr><tr><td>epoch</td><td>6</td></tr><tr><td>trainer/global_step</td><td>2794</td></tr><tr><td>val_loss</td><td>0.58305</td></tr><tr><td>val_accuracy</td><td>0.78567</td></tr><tr><td>test_loss</td><td>1.12878</td></tr><tr><td>test_accuracy</td><td>0.6388</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇█</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>▄▄▄▄▄▃▄▂▅▃▂▅▃▄▄▃▂█▄▃▄▄▃▇▄▃▁▃▄▃▅▃▃▃█▅▃▃▂▄</td></tr><tr><td>train_accuracy</td><td>▅▅▅▄▄▆▅▇▆▆▇▄▆▆▅▆▆▄▅▅▆▅▇▂▅▅█▅▆▇▄▆▆▆▁▄▅▅█▄</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██████</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>▄▅▃▁▅▅█</td></tr><tr><td>val_accuracy</td><td>▆▅▆█▅▄▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 41 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">northern-eon-57</strong>: <a href=\"https://wandb.ai/dodicin/mlops-project/runs/1so8owze\" target=\"_blank\">https://wandb.ai/dodicin/mlops-project/runs/1so8owze</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [[x, y] for (x, y) in zip(recall_micro, precision_micro)]\n",
    "sample_rate = int(len(data)/10000)\n",
    "\n",
    "table = wandb.Table(columns=[\"recall_micro\", \"precision_micro\"], data=data[::sample_rate])\n",
    "wandb.log({\"precision_recall\" : wandb.plot.line(table, \n",
    "                                                \"recall_micro\", \n",
    "                                                \"precision_micro\", \n",
    "                                                stroke=None, \n",
    "                                                title=\"Average Precision\")})\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1cb414",
   "metadata": {},
   "source": [
    "## Inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6832f45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">devoted-shape-58</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/dodicin/mlops-project\" target=\"_blank\">https://wandb.ai/dodicin/mlops-project</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/dodicin/mlops-project/runs/3miiwtbg\" target=\"_blank\">https://wandb.ai/dodicin/mlops-project/runs/3miiwtbg</a><br/>\n",
       "                Run data is saved locally in <code>/home/nassim/dev/mlops-project/wandb/run-20210901_132724-3miiwtbg</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "checkpoint_reference = f'{entity}/{project}/model-{run_id}:best' # Checkpoint ref from WandB\n",
    "run = wandb.init(project='mlops-project')\n",
    "artifact = run.use_artifact(checkpoint_reference, type='model')\n",
    "artifact_dir = artifact.download()\n",
    "model = ResNet18.load_from_checkpoint(Path(artifact_dir)/'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2ae00a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), torch.Size([1]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "num_classes = 10\n",
    "val_ratio = 0.15\n",
    "num_workers = 8\n",
    "dm = FashionMNISTDataModule(batch_size=batch_size, num_classes=num_classes, val_ratio=val_ratio, num_workers=8)\n",
    "dm.setup()\n",
    "\n",
    "val_samples = next(iter(dm.val_dataloader()))\n",
    "val_img, val_label = torch.squeeze(val_samples[0], 0), val_samples[1]\n",
    "val_img.shape, val_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0780845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference time: 9.328277+-1.484817ms\n"
     ]
    }
   ],
   "source": [
    "mean_syn, std_syn = measure_inference_time([1, 28, 28], model)\n",
    "print(\"Mean inference time: {:2f}+-{:2f}ms\".format(mean_syn, std_syn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22d1a347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferences per second: 480.186473\n"
     ]
    }
   ],
   "source": [
    "throughput = measure_throughput([1, 28, 28], model)\n",
    "print('Inferences per second: {:2f}'.format(throughput))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
